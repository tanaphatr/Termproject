import os
import sys
sys.stdout.reconfigure(encoding='utf-8')
import pandas as pd
import numpy as np
import joblib
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from flask import Flask, jsonify
from pycaret.regression import *

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from Datafile.load_data import load_dataps
from Preprocess.preprocess_data import preprocess_dataps

# ‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
product_codes = ["A1001", "A1002", "A1004", "A1034", "B1002", "B1003", "D1003"]
# product_codes = ["A1001", "A1002", "A1004", "A1034", "B1002", "B1003", "D1003"]

def add_time_features(df):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á time features"""
    df['day_of_week'] = df['Date'].dt.dayofweek
    df['month'] = df['Date'].dt.month
    df['quarter'] = df['Date'].dt.quarter
    df['year'] = df['Date'].dt.year
    df['day_of_year'] = df['Date'].dt.dayofyear
    
    # Add cyclical encoding for seasonal features
    df['month_sin'] = np.sin(2 * np.pi * df['month']/12)
    df['month_cos'] = np.cos(2 * np.pi * df['month']/12)
    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week']/7)
    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week']/7)
    return df

def add_new_features(df):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á features ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"""
    df['prev_day_diff'] = df['Quantity'] - df['Quantity'].shift(1)
    df['rolling_avg_60'] = df['Quantity'].rolling(window=60).mean()
    return df

def add_lag_features(df, lags=[1, 2, 3, 7, 14, 30]):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á lag features"""
    for lag in lags:
        df[f'sales_lag_{lag}'] = df['Quantity'].shift(lag)
    return df

def add_rolling_features(df):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á rolling statistics features"""
    windows = [7, 14, 30]
    for window in windows:
        df[f'sales_ma_{window}'] = df['Quantity'].rolling(window=window).mean()
        df[f'sales_std_{window}'] = df['Quantity'].rolling(window=window).std()
        df[f'sales_min_{window}'] = df['Quantity'].rolling(window=window).min()
        df[f'sales_max_{window}'] = df['Quantity'].rolling(window=window).max()
    return df

def add_noise(df, noise_factor=0.03):
    """‡πÄ‡∏û‡∏¥‡πà‡∏° noise ‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    df_noise = df.copy()
    noise = np.random.normal(0, noise_factor * df['Quantity'].std(), size=len(df))
    df_noise['Quantity'] = np.clip(df_noise['Quantity'] + noise, 0, None)  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ñ‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏•‡∏ö
    return df_noise

def time_shift(df, shifts=[-2, -1, 1, 2]):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÄ‡∏ß‡∏•‡∏≤"""
    df_shifted_all = pd.DataFrame()
    for shift in shifts:
        df_shifted = df.copy()
        df_shifted['Quantity'] = df_shifted['Quantity'].shift(shift).bfill()  # ‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏≤‡∏´‡∏≤‡∏¢
        df_shifted_all = pd.concat([df_shifted_all, df_shifted])
    return df_shifted_all

def scale_features(df, scale_factors=[0.95, 1.05]):
    """‡∏õ‡∏£‡∏±‡∏ö‡∏™‡πÄ‡∏Å‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    df_scaled_all = pd.DataFrame()
    for scale in scale_factors:
        df_scaled = df.copy()
        df_scaled['Quantity'] = df_scaled['Quantity'] * scale
        df_scaled_all = pd.concat([df_scaled_all, df_scaled])
    return df_scaled_all

def add_trend(df):
    """‡πÄ‡∏û‡∏¥‡πà‡∏° trend ‡πÉ‡∏´‡πâ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    df_trend = df.copy()
    df_trend['Quantity'] = df_trend['Quantity'] * (1 + np.linspace(0, 0.1, len(df)))
    return df_trend

def save_to_csv(df, filename):
    """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå CSV"""
    df.to_csv(filename, index=False)
    print(f"‚úÖ Data saved to {filename}")

def prepare_data(df, random_seed=42):
    """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    print("üîÑ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    
    df = df.copy()
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
    df = df.dropna(subset=['Date'])
    
    print("‚ûï ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏° features...")
    df = add_time_features(df)
    df = add_lag_features(df)
    df = add_new_features(df)
    df = add_rolling_features(df)
    df = df.dropna()
    
    print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥ Data Augmentation...")
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ï‡πà‡∏≤‡∏á‡πÜ
    np.random.seed(random_seed)
    df_noise = add_noise(df)
    df_shifted = time_shift(df)
    df_scaled = scale_features(df)
    df_trend = add_trend(df)
    
    # ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô
    df_augmented = pd.concat([df, df_noise, df_shifted, df_scaled, df_trend])
    df_augmented = df_augmented.sort_values('Date').reset_index(drop=True)
    df_augmented['Quantity'].fillna(df_augmented['Quantity'].mean(), inplace=True)
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô
    save_to_csv(df_augmented, 'augmented_data.csv')
    
    return df_augmented

def get_product_name(product_code):
    """‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏£‡∏´‡∏±‡∏™‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤"""
    if product_code == "A1001":
        return " Osida shoes"
    elif product_code == "A1002":
        return " Adda shoes"
    elif product_code == "A1004":
        return " Fashion shoes"
    elif product_code == "A1034":
        return " Court Shoes"
    elif product_code == "B1002":
        return " Long socks"
    elif product_code == "B1003":
        return " Short socks"
    elif product_code == "D1003":
        return " Mask pack"

def train_pycaret_model(df_augmented, product_code):
    """‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏î‡πâ‡∏ß‡∏¢ PyCaret"""
    print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• PyCaret ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {product_code}...")
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡∏π‡∏Å‡∏ù‡∏∂‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà
    base_dir = os.path.dirname(os.path.abspath(__file__))
    model_dir = os.path.join(base_dir, 'ModelPycaret')
    os.makedirs(model_dir, exist_ok=True)
    
    model_path = os.path.join(model_dir, f'pycaret_model_{product_code}.pkl')
    metrics_path = os.path.join(model_dir, f'model_metrics_{product_code}.csv')
    name_path = os.path.join(model_dir, f'model_name_{product_code}.csv')
    date_path = os.path.join(model_dir, f'last_trained_date_{product_code}.pkl')
    
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    should_train = True
    if os.path.exists(model_path) and os.path.exists(date_path):
        last_trained_date = joblib.load(date_path)
        if datetime.now() - last_trained_date < timedelta(days=30):
            print(f"‚è≥ ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {product_code}")
            # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
            model = joblib.load(model_path)
            model_metrics = pd.read_csv(metrics_path)
            model_name_df = pd.read_csv(name_path)
            model_name = model_name_df.iloc[0]['model_name']
            should_train = False
    
    if should_train:
        print(f"üõ†Ô∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {product_code}...")
        
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ PyCaret
        setup(
            data=df_augmented,
            target='Quantity',
            session_id=42,
            feature_selection=True,
            normalize=True,
            remove_outliers=True,
            train_size=0.6,
            fold=5,
        )
        
        # ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        best_model = compare_models()
        final_model = finalize_model(best_model)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
        X_train = get_config('X_train')
        X_train.to_csv(os.path.join(model_dir, f'transformed_training_data_{product_code}.csv'), index=False)
        
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ã‡πå‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•
        model_metrics = pull()
        model_name = best_model.__class__.__name__
        
        # ‡∏î‡∏∂‡∏á‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        model_params = best_model.get_params()
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        joblib.dump(final_model, model_path)
        model_metrics.to_csv(metrics_path, index=False)
        pd.DataFrame({'model_name': [model_name]}).to_csv(name_path, index=False)
        joblib.dump(datetime.now(), date_path)
        
        print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")
        
        return final_model, model_metrics, model_name, model_params
    else:
        return model, model_metrics, model_name, {}

def predict_next_sales(model, df_augmented):
    """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ"""
    # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    latest_data = df_augmented.iloc[-1:].copy()
    latest_data = latest_data.drop(columns=['Quantity'])
    
    # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢
    predicted_sales = model.predict(latest_data)
    
    # ‡∏î‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ß‡∏±‡∏ô
    predicted_date = df_augmented['Date'].iloc[-1] + pd.DateOffset(days=1)
    
    return predicted_sales[0], predicted_date

# ‡∏™‡∏£‡πâ‡∏≤‡∏á Flask app
app = Flask(__name__)

@app.route('/', methods=['GET'])
def predict_sales_api():
    print("üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    df = load_dataps()
    df_preprocessed = preprocess_dataps(df)
    
    predictions = {}
    
    for product_code in product_codes:
        print(f"üîÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {product_code}...")
        
        df_product = df_preprocessed[df_preprocessed['Product_code'] == product_code]
        
        if df_product.empty:
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {product_code} ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ...")
            continue
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        df_augmented = prepare_data(df_product)
        
        # ‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
        model, model_metrics, model_name, model_params = train_pycaret_model(df_augmented, product_code)
        
        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢
        print(f"üîÆ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {product_code}...")
        next_day_prediction, predicted_date = predict_next_sales(model, df_augmented)
        productname = get_product_name(product_code)
        
        # ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•
        # ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏•‡πá‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á
        model_name_cleaned = model_name.lower().replace(" ", "")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏î‡∏µ‡∏ö‡∏±‡∏Å
        print(f"üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•: {model_name}")
        print(f"üîç ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á: {model_metrics['Model'].tolist()}")
        
        # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö model_name ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏™‡∏ô‡πÉ‡∏à‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏•‡πá‡∏Å‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏ç‡πà‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á
        filtered_model_metrics = model_metrics[model_metrics['Model'].str.lower().str.replace(" ", "") == model_name_cleaned]
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠
        if filtered_model_metrics.empty:
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {model_name} ‡πÅ‡∏ö‡∏ö‡∏ï‡∏£‡∏á‡∏ä‡∏∑‡πà‡∏≠ ‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô...")
            
            # ‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•
            if 'lgbm' in model_name_cleaned:
                filtered_model_metrics = model_metrics[model_metrics['Model'].str.lower().str.contains('lgbm') | 
                                                      model_metrics['Model'].str.lower().str.contains('lightgbm')]
            else:
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏î‡πâ‡∏ß‡∏¢ 4 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•
                filtered_model_metrics = model_metrics[model_metrics['Model'].str.lower().str.contains(model_name_cleaned[:4])]
            
            # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏£‡∏Å‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á
            if filtered_model_metrics.empty and not model_metrics.empty:
                print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö {model_name} ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏£‡∏Å‡πÅ‡∏ó‡∏ô")
                filtered_model_metrics = model_metrics.iloc[:1]
        
        # ‡∏î‡∏∂‡∏á‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        metrics_dict = {}
        if not filtered_model_metrics.empty:
            metrics_cols = ['MAE', 'MAPE', 'RMSE', 'R2']
            available_cols = [col for col in metrics_cols if col in filtered_model_metrics.columns]
            if available_cols:
                metrics_dict = filtered_model_metrics[available_cols].iloc[0].to_dict()
                # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô float
                metrics_dict = {k: float(v) for k, v in metrics_dict.items()}
                print(f"‚úÖ ‡∏û‡∏ö‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {model_name}: {metrics_dict}")
            else:
                print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ: {filtered_model_metrics.columns.tolist()}")
        else:
            print(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏°‡∏ï‡∏£‡∏¥‡∏Å‡∏ã‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {model_name} ‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö")
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á
            print(f"‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á: {model_metrics['Model'].unique()}")
        
        print(f"üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {product_code}:")
        for metric, value in metrics_dict.items():
            print(f"{metric}: {value:.4f}")
        
        predictions[product_code + productname] = {
            'predicted_sales': int(next_day_prediction),
            'predicted_date': predicted_date.strftime("%Y-%m-%d"),
            'model_name': model_name,
            'metrics': metrics_dict,
            'model_params': model_params
        }
    
    return jsonify(predictions)

if __name__ == '__main__':
    app.run(host='localhost', port=8885, debug=True)