import os
import sys
import pandas as pd
import numpy as np
import joblib
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from flask import Flask, jsonify
from tensorflow.keras.models import Sequential # type: ignore
from tensorflow.keras.layers import LSTM, Dense, Dropout # type: ignore
from tensorflow.keras.optimizers import Adam # type: ignore
from tensorflow.keras import regularizers # type: ignore
from tensorflow.keras.losses import Huber # type: ignore
from tensorflow.keras.callbacks import EarlyStopping, Callback, ReduceLROnPlateau# type: ignore
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error ,r2_score


# ‡πÄ‡∏û‡∏¥‡πà‡∏° path ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..', 'PJML')))

from Datafile.load_data import load_data
from Preprocess.preprocess_data import preprocess_data

#===============================================‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•=========================================
def prepare_data(df):
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤ NaT ‡πÉ‡∏ô sale_date
    df['sale_date'] = pd.to_datetime(df['sale_date'], errors='coerce')
    df = df.dropna(subset=['sale_date'])

    # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå weather ‡πÅ‡∏•‡∏∞ event ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏Ç‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
    weather_columns = ['weather_Mostly_Sunny', 'weather_Partly_Cloudy', 'weather_Scattered_Shower']
    event_column = ['event_Normal_Day']

    df[weather_columns] = df[weather_columns].astype(int)
    df[event_column] = df[event_column].astype(int)

    # ‡∏™‡πÄ‡∏Å‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á [0, 1] ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå sales_amount
    scaler = MinMaxScaler()
    df['sales_amount_scaled'] = scaler.fit_transform(df[['sales_amount']])

    # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡πà‡∏≤‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Temperature (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    if 'Temperature' in df.columns:
        df['Temperature'] = df['Temperature'].fillna(df['Temperature'].mean())

    # ‚úÖ Data Augmentation (‡πÄ‡∏û‡∏¥‡πà‡∏° Noise ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢‡∏•‡∏î Overfitting)
    df['sales_amount_scaled'] += np.random.normal(0, 0.01, df.shape[0])

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LSTM
    sequence_length = 60
    X, y = [], []
    features = ['Temperature', 'Day', 'Month', 'Year'] + weather_columns + event_column
    for i in range(sequence_length, len(df)):
        X.append(df.iloc[i-sequence_length:i][features].values)
        y.append(df['sales_amount_scaled'].iloc[i])

    return np.array(X), np.array(y), scaler, df

#===============================================‡πÄ‡∏ó‡∏£‡∏ô=========================================
def train_lstm_model1(X_train, y_train, X_val, y_val):
    base_dir = os.path.dirname(os.path.abspath(__file__))
    model_dir = os.path.join(base_dir, 'ModelLstm1')

    model_path1 = os.path.join(model_dir, 'lstm_model1.pkl')
    date_path = os.path.join(model_dir, 'last_trained_date1.pkl')

    os.makedirs(model_dir, exist_ok=True)

    if os.path.exists(model_path1):
        model = joblib.load(model_path1)
        print("üì• ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß")

        if os.path.exists(date_path):
            last_trained_date = joblib.load(date_path)
        else:
            last_trained_date = datetime.min

        if datetime.now() - last_trained_date < timedelta(days=30):
            print("‚è≥ ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏´‡∏°‡πà (‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 30 ‡∏ß‡∏±‡∏ô)")
            return model
        else:
            print("üîÑ ‡∏ñ‡∏∂‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà!")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Callback Logger ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
    class EarlyStoppingLogger(Callback):
        def on_train_end(self, logs=None):
            print("‚ö†Ô∏è ‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏£‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏≤‡∏à‡πÄ‡∏Å‡∏¥‡∏î‡∏Å‡∏≤‡∏£ Overfitting!")

    early_stopping = EarlyStopping(
        monitor='val_loss',  # ‚úÖ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å loss -> val_loss
        patience=5,
        restore_best_weights=True
    )

    # ‚úÖ Learning Rate Schedule
    reduce_lr = ReduceLROnPlateau(
        monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5, verbose=1
    )

    model = Sequential([
        LSTM(256, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_regularizer=regularizers.l2(0.001)),
        Dropout(0.3),
        LSTM(128, return_sequences=True, kernel_regularizer=regularizers.l2(0.001)),  # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏° Regularization
        Dropout(0.3),
        LSTM(64, kernel_regularizer=regularizers.l2(0.001)),
        Dropout(0.3),
        Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),  # ‚úÖ Regularization
        Dense(1)
    ])

    model.compile(optimizer=Adam(learning_rate=0.0005), loss=Huber(), metrics=['mae', 'mape'])
    print("üõ†Ô∏è ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà...")

    model.fit(X_train, y_train, 
                        validation_data=(X_val, y_val),  # ‚úÖ ‡πÉ‡∏ä‡πâ Validation
                        epochs=30, batch_size=32, verbose=1, 
                        callbacks=[early_stopping, reduce_lr, EarlyStoppingLogger()])

    joblib.dump(model, model_path1)
    joblib.dump(datetime.now(), date_path)
    print("‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ó‡∏£‡∏ô‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß")

    return model

#===============================================‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢=========================================
def predict_next_sales(model, X, scaler, df):
    # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
    last_sequence = X[-1].reshape(1, -1, X.shape[2])
    prediction_scaled = model.predict(last_sequence)
    predicted_sales = scaler.inverse_transform(prediction_scaled)[0][0]
    
    # ‡∏î‡∏∂‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå 'sale_date' ‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ß‡∏±‡∏ô
    predicted_date = df['sale_date'].iloc[-1] + pd.DateOffset(days=1)
    return predicted_sales, predicted_date
    

#===============================================API=========================================

app = Flask(__name__)

@app.route('/', methods=['GET'])
def predict_sales_api():
    df = load_data()
    df_preprocessed = preprocess_data(df)

    X, y, scaler, df_prepared = prepare_data(df_preprocessed)

<<<<<<< HEAD
    # ‚úÖ ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô Train, Validation ‡πÅ‡∏•‡∏∞ Test
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, shuffle=False)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)
=======
    # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô Train ‡πÅ‡∏•‡∏∞ Test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
>>>>>>> 5a8c55dd4335f0ff13cf6d49a6dc7523735097e7

    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2])
    X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2])
    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2])

    model = train_lstm_model1(X_train, y_train, X_val, y_val)

    predicted_sales = model.predict(X_test)
    predicted_sales = scaler.inverse_transform(predicted_sales)

    y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1))

    mae = mean_absolute_error(predicted_sales, y_test_original)
    mape = mean_absolute_percentage_error(predicted_sales, y_test_original)
    r2 = r2_score(y_test_original, predicted_sales)

    predicted_date = df_prepared['sale_date'].iloc[-1] + pd.DateOffset(days=1)

    return jsonify({
        'predicted_sales': float(predicted_sales[-1][0]),
        'predicted_date': str(predicted_date),
        'model_name': "LSTM",
        'mae': mae,
        'mape': mape,
        'r2': r2
    })

if __name__ == '__main__':
    app.run(host='localhost', port=8885, debug=True)